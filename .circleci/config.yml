# UDACITY CAPSTONE PROJECT - CircleCI File Configuration ------
#In this project I applied the skills and knowledge developed throughout the Udacity Cloud DevOps Nanodegree program

version: 2.1

orbs:
  kubernetes: circleci/kubernetes@1.3.1
  aws-cli: circleci/aws-cli@3.1.3
  aws-eks: circleci/aws-eks@2.2.0
  anchore: anchore/anchore-engine@1.1.0

#parameters:
#  cluster-name:
#      type: string
#      default: "udacity-capstone-cluster"

commands:
  eks-cluster-destroy:
      description: Destroy EKS cluster in case of deployment failure
      steps:
        - run:
            name: Destry EKS cluster
            when: on_fail
            command: | 
              echo "Destroying eks cluster after deployment failure"
              eksctl delete cluster --region=us-east-1 --name=udacity-capstone-cluster
              echo ""EKS cluster and nodes successfully destroyed"

jobs:

  #Build and lint code
  build-lint-code:
    docker:
      - image: python:3.9-buster
    working_directory: ~/app
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "requirements.txt" }}
            - v1-dependencies-
      - run:
          name: install dependencies
          command: |
            python3 -m venv venv
            . venv/bin/activate
            make install
            wget -O /bin/hadolint https://github.com/hadolint/hadolint/releases/download/v1.16.3/hadolint-Linux-x86_64 &&\
            chmod +x /bin/hadolint
      - save_cache:
          paths:
            - ./venv
          key: v1-dependencies-{{ checksum "requirements.txt" }}
      - run:
          name: run lint
          command: |
            . venv/bin/activate
            make lint 
  
  docker-container:
    docker:
      - image: docker:17.05.0-ce-git
    executor: anchore/anchore_engine  
    working_directory: ~/app
    steps:
      - checkout
      - setup_remote_docker
      - run:
          name: install dependecies
          command: |
            apk update
            apk upgrade
            apk search curl
            apk --no-cache add curl
            apk add --upgrade net-tools-doc
            apk add --no-cache py-pip=9.0.0-r1
      - run:
          name: Build docker image and add a descriptive tag
          command: |
            docker build --build-arg build_number="${CIRCLE_BUILD_NUM}" -t udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5} .
      - run:
          name: List docker images
          command: |
            docker image ls
      - run:
          name: run docker image and push to docker hub
          command: |
            docker run -d -p 5000:5000 --name capstone udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5}
            docker ps
            dockerpath=$DOCKERHUB_USERNAME/udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5}
            echo "Docker ID and Image: $dockerpath"
            docker login -u="$DOCKERHUB_USERNAME" -p="$DOCKERHUB_PASSWORD"
            docker image tag udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5} $dockerpath
            docker push $dockerpath
      - run:
          name: Save Docker image
          command: |
            rm -rf /home/circleci/workspace/docker/
            mkdir /home/circleci/workspace/docker/ -p
            docker save -o /home/circleci/workspace/docker/udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5}.tar udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5}
      - persist_to_workspace:
          root: /home/circleci/workspace/
          paths:
            - docker/*

#  local_image_scan:
#    executor: anchore/anchore_engine
#    steps:
#      - attach_workspace:
#          at: /home/circleci/workspace/
#      - run:
#          name: Load Docker image layer cache
#          command: |
#            docker load -i /home/circleci/workspace/docker/udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5}.tar
#      - anchore/analyze_local_image:
#          image_name: udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5}
      
  deploy-network-infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      #installing tar - mandatory for creating workspaces in aws-cli image
      - run:
          name: Install dependencies 
          command: yum install -y tar gzip 
      #installo gettext se metto qui la creazione del file eksctl-cluster.yml 
      #install backend instance    
      - run:
          name: Create Backend infrastructure stack
          working_directory: ./.circleci/files
          command: |
            aws cloudformation deploy \
              --template-file network.yml \
              --tags project=udacity-capstone-${CIRCLE_WORKFLOW_ID:0:5} \
              --stack-name network-capstone-project \
              --no-fail-on-empty-changeset

#--> provare a estrarre i nomi delle varie subnet e vpc e inserirli come variabili nel file eksctl-cluster.yml     
      - run:
          name: extract vpc and subnet ids
          working_directory: ./.circleci/files
          command: |

            export VPC=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='VPC'].OutputValue" --output text)
            export PUBLIC_SUBNET_1=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PublicSubnet1'].OutputValue" --output text)
            export PUBLIC_SUBNET_2=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PublicSubnet2'].OutputValue" --output text)
            export PRIVATE_SUBNET_1=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet1'].OutputValue" --output text)
            export PRIVATE_SUBNET_2=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet2'].OutputValue" --output text)             
            echo "VPC = ${VPC}"
            echo "Public-Subnet-1 = ${PUBLIC_SUBNET_1}"
            echo "Public-Subnet-2 = ${PUBLIC_SUBNET_2}"
            echo "Private-Subnet-1 = ${PRIVATE_SUBNET_1}"
            echo "Private-Subnet-2 = ${PRIVATE_SUBNET_2}"
  
  #se esiste già il cluster? si può saltare questo step?
  create-eks-cluster: 
    docker:
      - image: python:3.9-buster
    steps:
      - checkout
      - aws-cli/install
      - run:
          name: check if cluster exist 
          command: | 
            aws eks list-clusters --region us-east-1 --output text > cluster.txt
            cat cluster.txt
            if grep -q "udacity-capstone-cluster" cluster.txt
            then
              echo "the cluster already exist"
              circleci-agent step halt
              exit 0
            else
              echo "the cluster doesn't exits"
            fi
      
      #install envsubst
      - run:
          name: Install dependencies
          command: |
            pip install envsubst  
      
      - run:
          name: Install iam authenticator
          command: |
            curl -o aws-iam-authenticator https://amazon-eks.s3.us-west-2.amazonaws.com/1.19.6/2021-01-05/bin/linux/amd64/aws-iam-authenticator
            chmod +x ./aws-iam-authenticator
            mkdir -p $HOME/bin && cp ./aws-iam-authenticator $HOME/bin/aws-iam-authenticator && export PATH=$PATH:$HOME/bin
            echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
            aws-iam-authenticator help
      - run:
          name: Install eksctl
          command: |
            curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
            mv /tmp/eksctl /usr/local/bin
            eksctl --help
      - run:
          name: Install kubectl
          command: |
            curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.20.4/2021-04-12/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
            echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
            kubectl version --short --client
      - run:
          name: Create cluster and worker nodes
          working_directory: ./.circleci/files
          command: |

            export VPC=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='VPC'].OutputValue" --output text)
            export PUBLIC_SUBNET_1=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PublicSubnet1'].OutputValue" --output text)
            export PUBLIC_SUBNET_2=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PublicSubnet2'].OutputValue" --output text)
            export PRIVATE_SUBNET_1=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet1'].OutputValue" --output text)
            export PRIVATE_SUBNET_2=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet2'].OutputValue" --output text)             
            echo "VPC = ${VPC}"
            echo "Public-Subnet-1 = ${PUBLIC_SUBNET_1}"
            echo "Public-Subnet-2 = ${PUBLIC_SUBNET_2}"
            echo "Private-Subnet-1 = ${PRIVATE_SUBNET_1}"
            echo "Private-Subnet-2 = ${PRIVATE_SUBNET_2}"
          
            curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.20.4/2021-04-12/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
            echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
            kubectl version --short --client
            
            envsubst < eksctl-cluster.yml | eksctl create cluster -f -
            
            kubectl get svc

 
  deploy-to-eks: 
    docker:
      - image: python:3.9-buster
    steps:
      - checkout
      - aws-cli/install
      - run:
          name: Install dependencies
          command: |
            pip install envsubst    
      - run:
          name: Update kubectl config 
          command: |
            aws eks --region us-east-1 update-kubeconfig --name udacity-capstone-cluster
      - run:
          name: Update kubectl config 
          command: |
            aws eks describe-cluster --name udacity-capstone-cluster
      - run:
          name: Apply kubectl deploy manifest
          working_directory: ./.circleci/files
          command: |
            curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.20.4/2021-04-12/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
            echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
            kubectl version --short --client
            export DOCKER_IMAGE="frenkell/udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5}"
            echo "Docker-Image = ${DOCKER_IMAGE}"
            envsubst < deployment.yml | kubectl apply -f -
            kubectl get deployments
      - run:
          name: Check kubernetes configuration
          command: |
            curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.20.4/2021-04-12/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
            echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
            kubectl version --short --client
            kubectl get pods -o wide
            kubectl get nodes -o wide
      
      - eks-cluster-destroy

  smoke-test:
    docker:
      - image: cimg/python:3.10
    steps:
      - checkout
      - kubernetes/install-kubectl:
            kubectl-version: v1.25.2
      - aws-eks/update-kubeconfig-with-authenticator:
            cluster-name: udacity-capstone-cluster
      - run:
          name: check kubernetes active services
          command: |
            kubectl get services
            ls
      - run:
          name: store udacity-capstone endpoint
          working_directory: ./.circleci/files
          command: |
            kubectl get services
            api=$(kubectl get services udacity-capstone --output jsonpath='{.status.loadBalancer.ingress[0].hostname}')
            echo $api >> capstone-endpoint.txt
            cat capstone-endpoint.txt
      - persist_to_workspace:
          root: .
          paths:
            - .circleci/files/capstone-endpoint.txt
      - run:
          name: Smoke test
          working_directory: ./.circleci/files
          command: |
            export CAPSTONE_IP=$(cat capstone-endpoint.txt)    
            export CAPSTONE_ENDPOINT="http://${CAPSTONE_IP}:5000"
            echo "Endpoint = ${CAPSTONE_ENDPOINT}"
            sleep 1m
            if curl --head ${CAPSTONE_ENDPOINT} | grep "HTTP/1.1 200 OK"
            then
              echo "smoke test performed successfully"
              exit 0  
            else
              echo "smoke test failed"
              exit 1
            fi

workflows:
 capstone:
    jobs:
      - build-lint-code:
          filters:
            branches:
              only: [main]
      - docker-container:
          requires: [build-lint-code]
          filters:
            branches:
              only: [main]   
      - local_image_scan: 
          requires: [build-lint-code, docker-container]
          filters:
            branches:
              only: [main]         
#      - deploy-network-infrastructure:
#          requires: [build-lint-code, docker-container]
#          filters:
#            branches:
#              only: [main]
#      - create-eks-cluster: 
#          requires: [build-lint-code, docker-container, deploy-network-infrastructure]
#          filters:
#            branches:
#              only: [main]
#      - deploy-to-eks:
#          requires: [build-lint-code, docker-container, deploy-network-infrastructure, create-eks-cluster]
#          filters:
#            branches:
#              only: [main]
#      - smoke-test:
#          requires: [build-lint-code, docker-container, deploy-network-infrastructure, create-eks-cluster, deploy-to-eks]
#          filters:
#            branches:
#              only: [main]
