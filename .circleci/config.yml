# UDACITY CAPSTONE PROJECT - CircleCI File Configuration ---
#In this project I applied the skills and knowledge developed throughout the Udacity Cloud DevOps Nanodegree program

version: 2.1

orbs:
  kubernetes: circleci/kubernetes@1.3.1
  aws-cli: circleci/aws-cli@3.1.3
  aws-eks: circleci/aws-eks@2.2.0

#parameters:
  #tipo il nome del cluster

commands:
  eks-cluster-destroy:
      description: Destroy EKS cluster in case of deployment failure
      steps:
        - run:
            name: Destry EKS cluster
            when: on_fail
            command: | 
              echo "Destroying eks cluster after deployment failure"
              eksctl delete cluster --region=us-east-1 --name=udacity-capstone-cluster
              echo ""EKS cluster and nodes successfully destroyed. For error see build-stage output""

jobs:
  
  #Build and lint code
  build-lint-code:
    docker:
      - image: python:3.9-buster
    working_directory: ~/app
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "requirements.txt" }}
            - v1-dependencies-
      - run:
          name: install dependencies
          command: |
            python3 -m venv venv
            . venv/bin/activate
            make install
            wget -O /bin/hadolint https://github.com/hadolint/hadolint/releases/download/v1.16.3/hadolint-Linux-x86_64 &&\
            chmod +x /bin/hadolint
      - save_cache:
          paths:
            - ./venv
          key: v1-dependencies-{{ checksum "requirements.txt" }}
      - run:
          name: run lint
          command: |
            . venv/bin/activate
            make lint 
  
  docker-container:
    docker:
      - image: docker:17.05.0-ce-git
    working_directory: ~/app
    steps:
      - checkout
      - setup_remote_docker
      - run:
          name: install dependecies
          command: |
            apk update
            apk upgrade
            apk search curl
            apk --no-cache add curl
            apk add --upgrade net-tools-doc
            apk add --no-cache py-pip=9.0.0-r1
      - run:
          name: Build docker image and add a descriptive tag
          command: |
            docker build --build-arg build_number="${CIRCLE_BUILD_NUM}" -t udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5} .
      - run:
          name: List docker images
          command: |
            docker image ls
      - run:
          name: run docker image and push to docker hub
          command: |
            docker run -d -p 5000:5000 --name capstone udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5}
            docker ps
            dockerpath=$DOCKERHUB_USERNAME/udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5}
            echo "Docker ID and Image: $dockerpath"
            docker login -u="$DOCKERHUB_USERNAME" -p="$DOCKERHUB_PASSWORD"
            docker image tag udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5} $dockerpath
            docker push $dockerpath

  # sbagliata la vpc CIDR? di base eksctl usa 192.168.0.0/16
  deploy-network-infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      #installing tar - mandatory for creating workspaces in aws-cli image
      - run:
          name: Install dependencies 
          command: yum install -y tar gzip 
      #installo gettext se metto qui la creazione del file eksctl-cluster.yml 
      #install backend instance    
      - run:
          name: Create Backend infrastructure stack
          working_directory: ./.circleci/files
          command: |
            aws cloudformation deploy \
              --template-file network.yml \
              --tags project=udacity-capstone-${CIRCLE_WORKFLOW_ID:0:5} \
              --stack-name network-capstone-project \
              --no-fail-on-empty-changeset

#--> provare a estrarre i nomi delle varie subnet e vpc e inserirli come variabili nel file eksctl-cluster.yml     
      - run:
          name: extract vpc and subnet ids
          working_directory: ./.circleci/files
          command: |

            export VPC=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='VPC'].OutputValue" --output text)
            export PUBLIC_SUBNET_1=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PublicSubnet1'].OutputValue" --output text)
            export PUBLIC_SUBNET_2=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PublicSubnet2'].OutputValue" --output text)
            export PRIVATE_SUBNET_1=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet1'].OutputValue" --output text)
            export PRIVATE_SUBNET_2=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet2'].OutputValue" --output text)             
            echo "VPC = ${VPC}"
            echo "Public-Subnet-1 = ${PUBLIC_SUBNET_1}"
            echo "Public-Subnet-2 = ${PUBLIC_SUBNET_2}"
            echo "Private-Subnet-1 = ${PRIVATE_SUBNET_1}"
            echo "Private-Subnet-2 = ${PRIVATE_SUBNET_2}"
  
  #se esiste già il cluster? si può saltare questo step?
  create-eks-cluster: 
    docker:
      - image: python:3.9-buster
    steps:
      - checkout
      - aws-cli/install
      - run:
          name: check if cluster exist 
          command: | 
            aws eks list-clusters --region us-east-1 --output text > cluster.txt
            cat cluster.txt
            if grep -q "udacity-capstone-cluster" cluster.txt
            then
              echo "the cluster already exist"
              circleci-agent step halt
              exit 0
            else
              echo "the cluster doesn't exits"
            fi
      
      #install envsubst
      - run:
          name: Install dependencies
          command: |
            pip install envsubst  
      
      - run:
          name: Install iam authenticator
          command: |
            curl -o aws-iam-authenticator https://amazon-eks.s3.us-west-2.amazonaws.com/1.19.6/2021-01-05/bin/linux/amd64/aws-iam-authenticator
            chmod +x ./aws-iam-authenticator
            mkdir -p $HOME/bin && cp ./aws-iam-authenticator $HOME/bin/aws-iam-authenticator && export PATH=$PATH:$HOME/bin
            echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
            aws-iam-authenticator help
      - run:
          name: Install eksctl
          command: |
            curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
            mv /tmp/eksctl /usr/local/bin
            eksctl --help
      - run:
          name: Install kubectl
          command: |
            curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.20.4/2021-04-12/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
            echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
            kubectl version --short --client
      - run:
          name: Create cluster and worker nodes
          working_directory: ./.circleci/files
          command: |
            curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.20.4/2021-04-12/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
            echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
            kubectl version --short --client
            eksctl create cluster -f eksctl-cluster.yml
            kubectl get svc

# Da capire se va messo qui o quando creo l'infrastruttura. Sarebbe da creare un file nuovo. Nel tutorial fa così:
# replace environment variables and write to new file
# envsubst < config.txt > confidential_config.txt
# Se non funziona con il file deployment.yml, usare questo metodo anche lì
#            export VPC=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='VPC'].OutputValue" --output text)
#            export PUBLIC_SUBNET_1=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PublicSubnet1'].OutputValue" --output text)
#            export PUBLIC_SUBNET_2=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PublicSubnet2'].OutputValue" --output text)
#            export PRIVATE_SUBNET_1=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet1'].OutputValue" --output text)
#            export PRIVATE_SUBNET_2=$(aws cloudformation describe-stacks --stack-name network-capstone-project --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet2'].OutputValue" --output text)             
#            echo "VPC = ${VPC}"
#            echo "Public-Subnet-1 = ${PUBLIC_SUBNET_1}"
#            echo "Public-Subnet-2 = ${PUBLIC_SUBNET_2}"
#            echo "Private-Subnet-1 = ${PRIVATE_SUBNET_1}"
#            echo "Private-Subnet-2 = ${PRIVATE_SUBNET_2}"
#            envsubst < eksctl-cluster.yml | eksctl create cluster -f      
      
      - run:
          name: Update kubectl config 
          command: |
            aws eks --region us-east-1 update-kubeconfig --name udacity-capstone-cluster
      - run:
          name: Update kubectl config 
          command: |
            aws eks describe-cluster --name udacity-capstone-cluster
      
      #parte di deploy manuale senza orbs
      - run:
          name: Apply kubectl deploy manifest
          working_directory: ./.circleci/files
          command: |
            curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.20.4/2021-04-12/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
            echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
            kubectl version --short --client
            
            export DOCKER_IMAGE="frenkell/udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5}"
            echo "Docker-Image = ${DOCKER_IMAGE}"
            envsubst < deployment.yml | kubectl apply -f -

            kubectl get deployments
      - run:
          name: Check kubernetes configuration
          command: |
            curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.20.4/2021-04-12/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
            echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
            kubectl version --short --client
            kubectl get pods -o wide
            kubectl get nodes -o wide
      
      - eks-cluster-destroy


#  deploy-to-eks:
#    docker:
#      - image: cimg/python:3.10
#    steps:
#      - checkout
#      - kubernetes/install-kubectl:
#            kubectl-version: v1.25.2
#      - aws-eks/update-kubeconfig-with-authenticator:
#            cluster-name: udacity-capstone-cluster
#      - run:
#          name: test
#          command: |
#            kubectl get services
#            ls
#      - kubernetes/create-or-update-resource:
#          get-rollout-status: true
#          resource-file-path: ./.circleci/files/deployment.yml
#          resource-name: frenkell/udacity-capstone
#          show-kubectl-command: true
#      - run:
#          name: store app endpoint and old
#          working_directory: ./.circleci/files
#          command: |
#            kubectl get services
#            api=$(kubectl get services udacity-capstone:ver-${CIRCLE_WORKFLOW_ID:0:5} --output jsonpath='{.status.loadBalancer.ingress[0].hostname}')
#            echo $api >> capstone-endpoint.txt
#            cat app-endpoint.txt
#      - persist_to_workspace:
#          root: ~/
#          paths:
#            - .circleci/files/capstone-endpoint.txt

workflows:
 capstone:
    jobs:
      - build-lint-code
      - docker-container:
          requires: [build-lint-code]
      - deploy-network-infrastructure:
          requires: [docker-container]
      - create-eks-cluster: 
          requires: [build-lint-code, docker-container, deploy-network-infrastructure]
#      - deploy-to-eks:
#          requires: [build-lint-code, docker-container, deploy-network-infrastructure, create-eks-cluster]
#      - smoke-test:
#          requires: [build-lint-code, docker-container, deploy-network-infrastructure, create-eks-cluster, smoke-test]
